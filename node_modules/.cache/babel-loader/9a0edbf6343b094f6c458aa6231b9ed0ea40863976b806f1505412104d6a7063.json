{"ast":null,"code":"/*\n * Copyright (c) AXA Group Operations Spain S.A.\n *\n * Permission is hereby granted, free of charge, to any person obtaining\n * a copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sublicense, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be\n * included in all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n */\n\nconst {\n  LangAr,\n  NormalizerAr,\n  SentimentAr,\n  StemmerAr,\n  StopwordsAr,\n  TokenizerAr\n} = require('@nlpjs/lang-ar');\nconst {\n  LangBn,\n  NormalizerBn,\n  SentimentBn,\n  StemmerBn,\n  StopwordsBn,\n  TokenizerBn\n} = require('@nlpjs/lang-bn');\nconst {\n  LangCa,\n  NormalizerCa,\n  SentimentCa,\n  StemmerCa,\n  StopwordsCa,\n  TokenizerCa\n} = require('@nlpjs/lang-ca');\nconst {\n  LangCs,\n  NormalizerCs,\n  SentimentCs,\n  StemmerCs,\n  StopwordsCs,\n  TokenizerCs\n} = require('@nlpjs/lang-cs');\nconst {\n  LangDa,\n  NormalizerDa,\n  SentimentDa,\n  StemmerDa,\n  StopwordsDa,\n  TokenizerDa\n} = require('@nlpjs/lang-da');\nconst {\n  LangDe,\n  NormalizerDe,\n  SentimentDe,\n  StemmerDe,\n  StopwordsDe,\n  TokenizerDe\n} = require('@nlpjs/lang-de');\nconst {\n  LangEl,\n  NormalizerEl,\n  SentimentEl,\n  StemmerEl,\n  StopwordsEl,\n  TokenizerEl\n} = require('@nlpjs/lang-el');\nconst {\n  LangEn,\n  NormalizerEn,\n  SentimentEn,\n  StemmerEn,\n  StopwordsEn,\n  TokenizerEn\n} = require('@nlpjs/lang-en');\nconst {\n  LangEs,\n  NormalizerEs,\n  SentimentEs,\n  StemmerEs,\n  StopwordsEs,\n  TokenizerEs\n} = require('@nlpjs/lang-es');\nconst {\n  LangEu,\n  NormalizerEu,\n  SentimentEu,\n  StemmerEu,\n  StopwordsEu,\n  TokenizerEu\n} = require('@nlpjs/lang-eu');\nconst {\n  LangFa,\n  NormalizerFa,\n  SentimentFa,\n  StemmerFa,\n  StopwordsFa,\n  TokenizerFa\n} = require('@nlpjs/lang-fa');\nconst {\n  LangFi,\n  NormalizerFi,\n  SentimentFi,\n  StemmerFi,\n  StopwordsFi,\n  TokenizerFi\n} = require('@nlpjs/lang-fi');\nconst {\n  LangFr,\n  NormalizerFr,\n  SentimentFr,\n  StemmerFr,\n  StopwordsFr,\n  TokenizerFr\n} = require('@nlpjs/lang-fr');\nconst {\n  LangGa,\n  NormalizerGa,\n  SentimentGa,\n  StemmerGa,\n  StopwordsGa,\n  TokenizerGa\n} = require('@nlpjs/lang-ga');\nconst {\n  LangGl,\n  NormalizerGl,\n  SentimentGl,\n  StemmerGl,\n  StopwordsGl,\n  TokenizerGl\n} = require('@nlpjs/lang-gl');\nconst {\n  LangHi,\n  NormalizerHi,\n  SentimentHi,\n  StemmerHi,\n  StopwordsHi,\n  TokenizerHi\n} = require('@nlpjs/lang-hi');\nconst {\n  LangHu,\n  NormalizerHu,\n  SentimentHu,\n  StemmerHu,\n  StopwordsHu,\n  TokenizerHu\n} = require('@nlpjs/lang-hu');\nconst {\n  LangHy,\n  NormalizerHy,\n  SentimentHy,\n  StemmerHy,\n  StopwordsHy,\n  TokenizerHy\n} = require('@nlpjs/lang-hy');\nconst {\n  LangId,\n  NormalizerId,\n  SentimentId,\n  StemmerId,\n  StopwordsId,\n  TokenizerId\n} = require('@nlpjs/lang-id');\nconst {\n  LangIt,\n  NormalizerIt,\n  SentimentIt,\n  StemmerIt,\n  StopwordsIt,\n  TokenizerIt\n} = require('@nlpjs/lang-it');\nconst {\n  LangJa,\n  NormalizerJa,\n  SentimentJa,\n  StemmerJa,\n  StopwordsJa,\n  TokenizerJa\n} = require('@nlpjs/lang-ja');\nconst {\n  LangKo,\n  NormalizerKo,\n  SentimentKo,\n  StemmerKo,\n  StopwordsKo,\n  TokenizerKo\n} = require('@nlpjs/lang-ko');\nconst {\n  LangLt,\n  NormalizerLt,\n  SentimentLt,\n  StemmerLt,\n  StopwordsLt,\n  TokenizerLt\n} = require('@nlpjs/lang-lt');\nconst {\n  LangMs,\n  NormalizerMs,\n  SentimentMs,\n  StemmerMs,\n  StopwordsMs,\n  TokenizerMs\n} = require('@nlpjs/lang-ms');\nconst {\n  LangNe,\n  NormalizerNe,\n  SentimentNe,\n  StemmerNe,\n  StopwordsNe,\n  TokenizerNe\n} = require('@nlpjs/lang-ne');\nconst {\n  LangNl,\n  NormalizerNl,\n  SentimentNl,\n  StemmerNl,\n  StopwordsNl,\n  TokenizerNl\n} = require('@nlpjs/lang-nl');\nconst {\n  LangNo,\n  NormalizerNo,\n  SentimentNo,\n  StemmerNo,\n  StopwordsNo,\n  TokenizerNo\n} = require('@nlpjs/lang-no');\nconst {\n  LangPl,\n  NormalizerPl,\n  SentimentPl,\n  StemmerPl,\n  StopwordsPl,\n  TokenizerPl\n} = require('@nlpjs/lang-pl');\nconst {\n  LangPt,\n  NormalizerPt,\n  SentimentPt,\n  StemmerPt,\n  StopwordsPt,\n  TokenizerPt\n} = require('@nlpjs/lang-pt');\nconst {\n  LangRo,\n  NormalizerRo,\n  SentimentRo,\n  StemmerRo,\n  StopwordsRo,\n  TokenizerRo\n} = require('@nlpjs/lang-ro');\nconst {\n  LangRu,\n  NormalizerRu,\n  SentimentRu,\n  StemmerRu,\n  StopwordsRu,\n  TokenizerRu\n} = require('@nlpjs/lang-ru');\nconst {\n  LangSl,\n  NormalizerSl,\n  SentimentSl,\n  StemmerSl,\n  StopwordsSl,\n  TokenizerSl\n} = require('@nlpjs/lang-sl');\nconst {\n  LangSr,\n  NormalizerSr,\n  SentimentSr,\n  StemmerSr,\n  StopwordsSr,\n  TokenizerSr\n} = require('@nlpjs/lang-sr');\nconst {\n  LangSv,\n  NormalizerSv,\n  SentimentSv,\n  StemmerSv,\n  StopwordsSv,\n  TokenizerSv\n} = require('@nlpjs/lang-sv');\nconst {\n  LangTa,\n  NormalizerTa,\n  SentimentTa,\n  StemmerTa,\n  StopwordsTa,\n  TokenizerTa\n} = require('@nlpjs/lang-ta');\nconst {\n  LangTh,\n  NormalizerTh,\n  SentimentTh,\n  StemmerTh,\n  StopwordsTh,\n  TokenizerTh\n} = require('@nlpjs/lang-th');\nconst {\n  LangTl,\n  NormalizerTl,\n  SentimentTl,\n  StemmerTl,\n  StopwordsTl,\n  TokenizerTl\n} = require('@nlpjs/lang-tl');\nconst {\n  LangTr,\n  NormalizerTr,\n  SentimentTr,\n  StemmerTr,\n  StopwordsTr,\n  TokenizerTr\n} = require('@nlpjs/lang-tr');\nconst {\n  LangUk,\n  NormalizerUk,\n  SentimentUk,\n  StemmerUk,\n  StopwordsUk,\n  TokenizerUk\n} = require('@nlpjs/lang-uk');\nconst {\n  LangZh,\n  NormalizerZh,\n  SentimentZh,\n  StemmerZh,\n  StopwordsZh,\n  TokenizerZh\n} = require('@nlpjs/lang-zh');\nconst LangAll = require('./lang-all');\nconst {\n  langDict,\n  getNormalizer,\n  getTokenizer,\n  getStemmer,\n  getStopwords,\n  getSentiment,\n  normalize,\n  tokenize,\n  stem,\n  removeStopwords,\n  dict,\n  bow\n} = require('./lang-functions');\nmodule.exports = {\n  LangAll,\n  LangAr,\n  NormalizerAr,\n  SentimentAr,\n  StemmerAr,\n  StopwordsAr,\n  TokenizerAr,\n  LangBn,\n  NormalizerBn,\n  SentimentBn,\n  StemmerBn,\n  StopwordsBn,\n  TokenizerBn,\n  LangCa,\n  NormalizerCa,\n  SentimentCa,\n  StemmerCa,\n  StopwordsCa,\n  TokenizerCa,\n  LangCs,\n  NormalizerCs,\n  SentimentCs,\n  StemmerCs,\n  StopwordsCs,\n  TokenizerCs,\n  LangDa,\n  NormalizerDa,\n  SentimentDa,\n  StemmerDa,\n  StopwordsDa,\n  TokenizerDa,\n  LangDe,\n  NormalizerDe,\n  SentimentDe,\n  StemmerDe,\n  StopwordsDe,\n  TokenizerDe,\n  LangEl,\n  NormalizerEl,\n  SentimentEl,\n  StemmerEl,\n  StopwordsEl,\n  TokenizerEl,\n  LangEn,\n  NormalizerEn,\n  SentimentEn,\n  StemmerEn,\n  StopwordsEn,\n  TokenizerEn,\n  LangEs,\n  NormalizerEs,\n  SentimentEs,\n  StemmerEs,\n  StopwordsEs,\n  TokenizerEs,\n  LangEu,\n  NormalizerEu,\n  SentimentEu,\n  StemmerEu,\n  StopwordsEu,\n  TokenizerEu,\n  LangFa,\n  NormalizerFa,\n  SentimentFa,\n  StemmerFa,\n  StopwordsFa,\n  TokenizerFa,\n  LangFi,\n  NormalizerFi,\n  SentimentFi,\n  StemmerFi,\n  StopwordsFi,\n  TokenizerFi,\n  LangFr,\n  NormalizerFr,\n  SentimentFr,\n  StemmerFr,\n  StopwordsFr,\n  TokenizerFr,\n  LangGa,\n  NormalizerGa,\n  SentimentGa,\n  StemmerGa,\n  StopwordsGa,\n  TokenizerGa,\n  LangGl,\n  NormalizerGl,\n  SentimentGl,\n  StemmerGl,\n  StopwordsGl,\n  TokenizerGl,\n  LangHi,\n  NormalizerHi,\n  SentimentHi,\n  StemmerHi,\n  StopwordsHi,\n  TokenizerHi,\n  LangHu,\n  NormalizerHu,\n  SentimentHu,\n  StemmerHu,\n  StopwordsHu,\n  TokenizerHu,\n  LangHy,\n  NormalizerHy,\n  SentimentHy,\n  StemmerHy,\n  StopwordsHy,\n  TokenizerHy,\n  LangIt,\n  NormalizerIt,\n  SentimentIt,\n  StemmerIt,\n  StopwordsIt,\n  TokenizerIt,\n  LangId,\n  NormalizerId,\n  SentimentId,\n  StemmerId,\n  StopwordsId,\n  TokenizerId,\n  LangJa,\n  NormalizerJa,\n  SentimentJa,\n  StemmerJa,\n  StopwordsJa,\n  TokenizerJa,\n  LangKo,\n  NormalizerKo,\n  SentimentKo,\n  StemmerKo,\n  StopwordsKo,\n  TokenizerKo,\n  LangLt,\n  NormalizerLt,\n  SentimentLt,\n  StemmerLt,\n  StopwordsLt,\n  TokenizerLt,\n  LangMs,\n  NormalizerMs,\n  SentimentMs,\n  StemmerMs,\n  StopwordsMs,\n  TokenizerMs,\n  LangNe,\n  NormalizerNe,\n  SentimentNe,\n  StemmerNe,\n  StopwordsNe,\n  TokenizerNe,\n  LangNl,\n  NormalizerNl,\n  SentimentNl,\n  StemmerNl,\n  StopwordsNl,\n  TokenizerNl,\n  LangNo,\n  NormalizerNo,\n  SentimentNo,\n  StemmerNo,\n  StopwordsNo,\n  TokenizerNo,\n  LangPl,\n  NormalizerPl,\n  SentimentPl,\n  StemmerPl,\n  StopwordsPl,\n  TokenizerPl,\n  LangPt,\n  NormalizerPt,\n  SentimentPt,\n  StemmerPt,\n  StopwordsPt,\n  TokenizerPt,\n  LangRo,\n  NormalizerRo,\n  SentimentRo,\n  StemmerRo,\n  StopwordsRo,\n  TokenizerRo,\n  LangRu,\n  NormalizerRu,\n  SentimentRu,\n  StemmerRu,\n  StopwordsRu,\n  TokenizerRu,\n  LangSl,\n  NormalizerSl,\n  SentimentSl,\n  StemmerSl,\n  StopwordsSl,\n  TokenizerSl,\n  LangSr,\n  NormalizerSr,\n  SentimentSr,\n  StemmerSr,\n  StopwordsSr,\n  TokenizerSr,\n  LangSv,\n  NormalizerSv,\n  SentimentSv,\n  StemmerSv,\n  StopwordsSv,\n  TokenizerSv,\n  LangTa,\n  NormalizerTa,\n  SentimentTa,\n  StemmerTa,\n  StopwordsTa,\n  TokenizerTa,\n  LangTh,\n  NormalizerTh,\n  SentimentTh,\n  StemmerTh,\n  StopwordsTh,\n  TokenizerTh,\n  LangTl,\n  NormalizerTl,\n  SentimentTl,\n  StemmerTl,\n  StopwordsTl,\n  TokenizerTl,\n  LangTr,\n  NormalizerTr,\n  SentimentTr,\n  StemmerTr,\n  StopwordsTr,\n  TokenizerTr,\n  LangUk,\n  NormalizerUk,\n  SentimentUk,\n  StemmerUk,\n  StopwordsUk,\n  TokenizerUk,\n  LangZh,\n  NormalizerZh,\n  SentimentZh,\n  StemmerZh,\n  StopwordsZh,\n  TokenizerZh,\n  langDict,\n  getNormalizer,\n  getTokenizer,\n  getStemmer,\n  getStopwords,\n  getSentiment,\n  normalize,\n  tokenize,\n  stem,\n  removeStopwords,\n  dict,\n  bow\n};","map":{"version":3,"names":["LangAr","NormalizerAr","SentimentAr","StemmerAr","StopwordsAr","TokenizerAr","require","LangBn","NormalizerBn","SentimentBn","StemmerBn","StopwordsBn","TokenizerBn","LangCa","NormalizerCa","SentimentCa","StemmerCa","StopwordsCa","TokenizerCa","LangCs","NormalizerCs","SentimentCs","StemmerCs","StopwordsCs","TokenizerCs","LangDa","NormalizerDa","SentimentDa","StemmerDa","StopwordsDa","TokenizerDa","LangDe","NormalizerDe","SentimentDe","StemmerDe","StopwordsDe","TokenizerDe","LangEl","NormalizerEl","SentimentEl","StemmerEl","StopwordsEl","TokenizerEl","LangEn","NormalizerEn","SentimentEn","StemmerEn","StopwordsEn","TokenizerEn","LangEs","NormalizerEs","SentimentEs","StemmerEs","StopwordsEs","TokenizerEs","LangEu","NormalizerEu","SentimentEu","StemmerEu","StopwordsEu","TokenizerEu","LangFa","NormalizerFa","SentimentFa","StemmerFa","StopwordsFa","TokenizerFa","LangFi","NormalizerFi","SentimentFi","StemmerFi","StopwordsFi","TokenizerFi","LangFr","NormalizerFr","SentimentFr","StemmerFr","StopwordsFr","TokenizerFr","LangGa","NormalizerGa","SentimentGa","StemmerGa","StopwordsGa","TokenizerGa","LangGl","NormalizerGl","SentimentGl","StemmerGl","StopwordsGl","TokenizerGl","LangHi","NormalizerHi","SentimentHi","StemmerHi","StopwordsHi","TokenizerHi","LangHu","NormalizerHu","SentimentHu","StemmerHu","StopwordsHu","TokenizerHu","LangHy","NormalizerHy","SentimentHy","StemmerHy","StopwordsHy","TokenizerHy","LangId","NormalizerId","SentimentId","StemmerId","StopwordsId","TokenizerId","LangIt","NormalizerIt","SentimentIt","StemmerIt","StopwordsIt","TokenizerIt","LangJa","NormalizerJa","SentimentJa","StemmerJa","StopwordsJa","TokenizerJa","LangKo","NormalizerKo","SentimentKo","StemmerKo","StopwordsKo","TokenizerKo","LangLt","NormalizerLt","SentimentLt","StemmerLt","StopwordsLt","TokenizerLt","LangMs","NormalizerMs","SentimentMs","StemmerMs","StopwordsMs","TokenizerMs","LangNe","NormalizerNe","SentimentNe","StemmerNe","StopwordsNe","TokenizerNe","LangNl","NormalizerNl","SentimentNl","StemmerNl","StopwordsNl","TokenizerNl","LangNo","NormalizerNo","SentimentNo","StemmerNo","StopwordsNo","TokenizerNo","LangPl","NormalizerPl","SentimentPl","StemmerPl","StopwordsPl","TokenizerPl","LangPt","NormalizerPt","SentimentPt","StemmerPt","StopwordsPt","TokenizerPt","LangRo","NormalizerRo","SentimentRo","StemmerRo","StopwordsRo","TokenizerRo","LangRu","NormalizerRu","SentimentRu","StemmerRu","StopwordsRu","TokenizerRu","LangSl","NormalizerSl","SentimentSl","StemmerSl","StopwordsSl","TokenizerSl","LangSr","NormalizerSr","SentimentSr","StemmerSr","StopwordsSr","TokenizerSr","LangSv","NormalizerSv","SentimentSv","StemmerSv","StopwordsSv","TokenizerSv","LangTa","NormalizerTa","SentimentTa","StemmerTa","StopwordsTa","TokenizerTa","LangTh","NormalizerTh","SentimentTh","StemmerTh","StopwordsTh","TokenizerTh","LangTl","NormalizerTl","SentimentTl","StemmerTl","StopwordsTl","TokenizerTl","LangTr","NormalizerTr","SentimentTr","StemmerTr","StopwordsTr","TokenizerTr","LangUk","NormalizerUk","SentimentUk","StemmerUk","StopwordsUk","TokenizerUk","LangZh","NormalizerZh","SentimentZh","StemmerZh","StopwordsZh","TokenizerZh","LangAll","langDict","getNormalizer","getTokenizer","getStemmer","getStopwords","getSentiment","normalize","tokenize","stem","removeStopwords","dict","bow","module","exports"],"sources":["/Users/zyq/Desktop/大二下/暑期实习/moonshot project/node_modules/@nlpjs/lang-all/src/index.js"],"sourcesContent":["/*\n * Copyright (c) AXA Group Operations Spain S.A.\n *\n * Permission is hereby granted, free of charge, to any person obtaining\n * a copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sublicense, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be\n * included in all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n */\n\nconst {\n  LangAr,\n  NormalizerAr,\n  SentimentAr,\n  StemmerAr,\n  StopwordsAr,\n  TokenizerAr,\n} = require('@nlpjs/lang-ar');\nconst {\n  LangBn,\n  NormalizerBn,\n  SentimentBn,\n  StemmerBn,\n  StopwordsBn,\n  TokenizerBn,\n} = require('@nlpjs/lang-bn');\nconst {\n  LangCa,\n  NormalizerCa,\n  SentimentCa,\n  StemmerCa,\n  StopwordsCa,\n  TokenizerCa,\n} = require('@nlpjs/lang-ca');\nconst {\n  LangCs,\n  NormalizerCs,\n  SentimentCs,\n  StemmerCs,\n  StopwordsCs,\n  TokenizerCs,\n} = require('@nlpjs/lang-cs');\nconst {\n  LangDa,\n  NormalizerDa,\n  SentimentDa,\n  StemmerDa,\n  StopwordsDa,\n  TokenizerDa,\n} = require('@nlpjs/lang-da');\nconst {\n  LangDe,\n  NormalizerDe,\n  SentimentDe,\n  StemmerDe,\n  StopwordsDe,\n  TokenizerDe,\n} = require('@nlpjs/lang-de');\nconst {\n  LangEl,\n  NormalizerEl,\n  SentimentEl,\n  StemmerEl,\n  StopwordsEl,\n  TokenizerEl,\n} = require('@nlpjs/lang-el');\nconst {\n  LangEn,\n  NormalizerEn,\n  SentimentEn,\n  StemmerEn,\n  StopwordsEn,\n  TokenizerEn,\n} = require('@nlpjs/lang-en');\nconst {\n  LangEs,\n  NormalizerEs,\n  SentimentEs,\n  StemmerEs,\n  StopwordsEs,\n  TokenizerEs,\n} = require('@nlpjs/lang-es');\nconst {\n  LangEu,\n  NormalizerEu,\n  SentimentEu,\n  StemmerEu,\n  StopwordsEu,\n  TokenizerEu,\n} = require('@nlpjs/lang-eu');\nconst {\n  LangFa,\n  NormalizerFa,\n  SentimentFa,\n  StemmerFa,\n  StopwordsFa,\n  TokenizerFa,\n} = require('@nlpjs/lang-fa');\nconst {\n  LangFi,\n  NormalizerFi,\n  SentimentFi,\n  StemmerFi,\n  StopwordsFi,\n  TokenizerFi,\n} = require('@nlpjs/lang-fi');\nconst {\n  LangFr,\n  NormalizerFr,\n  SentimentFr,\n  StemmerFr,\n  StopwordsFr,\n  TokenizerFr,\n} = require('@nlpjs/lang-fr');\nconst {\n  LangGa,\n  NormalizerGa,\n  SentimentGa,\n  StemmerGa,\n  StopwordsGa,\n  TokenizerGa,\n} = require('@nlpjs/lang-ga');\nconst {\n  LangGl,\n  NormalizerGl,\n  SentimentGl,\n  StemmerGl,\n  StopwordsGl,\n  TokenizerGl,\n} = require('@nlpjs/lang-gl');\nconst {\n  LangHi,\n  NormalizerHi,\n  SentimentHi,\n  StemmerHi,\n  StopwordsHi,\n  TokenizerHi,\n} = require('@nlpjs/lang-hi');\nconst {\n  LangHu,\n  NormalizerHu,\n  SentimentHu,\n  StemmerHu,\n  StopwordsHu,\n  TokenizerHu,\n} = require('@nlpjs/lang-hu');\nconst {\n  LangHy,\n  NormalizerHy,\n  SentimentHy,\n  StemmerHy,\n  StopwordsHy,\n  TokenizerHy,\n} = require('@nlpjs/lang-hy');\nconst {\n  LangId,\n  NormalizerId,\n  SentimentId,\n  StemmerId,\n  StopwordsId,\n  TokenizerId,\n} = require('@nlpjs/lang-id');\nconst {\n  LangIt,\n  NormalizerIt,\n  SentimentIt,\n  StemmerIt,\n  StopwordsIt,\n  TokenizerIt,\n} = require('@nlpjs/lang-it');\nconst {\n  LangJa,\n  NormalizerJa,\n  SentimentJa,\n  StemmerJa,\n  StopwordsJa,\n  TokenizerJa,\n} = require('@nlpjs/lang-ja');\nconst {\n  LangKo,\n  NormalizerKo,\n  SentimentKo,\n  StemmerKo,\n  StopwordsKo,\n  TokenizerKo,\n} = require('@nlpjs/lang-ko');\nconst {\n  LangLt,\n  NormalizerLt,\n  SentimentLt,\n  StemmerLt,\n  StopwordsLt,\n  TokenizerLt,\n} = require('@nlpjs/lang-lt');\nconst {\n  LangMs,\n  NormalizerMs,\n  SentimentMs,\n  StemmerMs,\n  StopwordsMs,\n  TokenizerMs,\n} = require('@nlpjs/lang-ms');\nconst {\n  LangNe,\n  NormalizerNe,\n  SentimentNe,\n  StemmerNe,\n  StopwordsNe,\n  TokenizerNe,\n} = require('@nlpjs/lang-ne');\nconst {\n  LangNl,\n  NormalizerNl,\n  SentimentNl,\n  StemmerNl,\n  StopwordsNl,\n  TokenizerNl,\n} = require('@nlpjs/lang-nl');\nconst {\n  LangNo,\n  NormalizerNo,\n  SentimentNo,\n  StemmerNo,\n  StopwordsNo,\n  TokenizerNo,\n} = require('@nlpjs/lang-no');\nconst {\n  LangPl,\n  NormalizerPl,\n  SentimentPl,\n  StemmerPl,\n  StopwordsPl,\n  TokenizerPl,\n} = require('@nlpjs/lang-pl');\nconst {\n  LangPt,\n  NormalizerPt,\n  SentimentPt,\n  StemmerPt,\n  StopwordsPt,\n  TokenizerPt,\n} = require('@nlpjs/lang-pt');\nconst {\n  LangRo,\n  NormalizerRo,\n  SentimentRo,\n  StemmerRo,\n  StopwordsRo,\n  TokenizerRo,\n} = require('@nlpjs/lang-ro');\nconst {\n  LangRu,\n  NormalizerRu,\n  SentimentRu,\n  StemmerRu,\n  StopwordsRu,\n  TokenizerRu,\n} = require('@nlpjs/lang-ru');\nconst {\n  LangSl,\n  NormalizerSl,\n  SentimentSl,\n  StemmerSl,\n  StopwordsSl,\n  TokenizerSl,\n} = require('@nlpjs/lang-sl');\nconst {\n  LangSr,\n  NormalizerSr,\n  SentimentSr,\n  StemmerSr,\n  StopwordsSr,\n  TokenizerSr,\n} = require('@nlpjs/lang-sr');\nconst {\n  LangSv,\n  NormalizerSv,\n  SentimentSv,\n  StemmerSv,\n  StopwordsSv,\n  TokenizerSv,\n} = require('@nlpjs/lang-sv');\nconst {\n  LangTa,\n  NormalizerTa,\n  SentimentTa,\n  StemmerTa,\n  StopwordsTa,\n  TokenizerTa,\n} = require('@nlpjs/lang-ta');\nconst {\n  LangTh,\n  NormalizerTh,\n  SentimentTh,\n  StemmerTh,\n  StopwordsTh,\n  TokenizerTh,\n} = require('@nlpjs/lang-th');\nconst {\n  LangTl,\n  NormalizerTl,\n  SentimentTl,\n  StemmerTl,\n  StopwordsTl,\n  TokenizerTl,\n} = require('@nlpjs/lang-tl');\nconst {\n  LangTr,\n  NormalizerTr,\n  SentimentTr,\n  StemmerTr,\n  StopwordsTr,\n  TokenizerTr,\n} = require('@nlpjs/lang-tr');\nconst {\n  LangUk,\n  NormalizerUk,\n  SentimentUk,\n  StemmerUk,\n  StopwordsUk,\n  TokenizerUk,\n} = require('@nlpjs/lang-uk');\nconst {\n  LangZh,\n  NormalizerZh,\n  SentimentZh,\n  StemmerZh,\n  StopwordsZh,\n  TokenizerZh,\n} = require('@nlpjs/lang-zh');\nconst LangAll = require('./lang-all');\n\nconst {\n  langDict,\n  getNormalizer,\n  getTokenizer,\n  getStemmer,\n  getStopwords,\n  getSentiment,\n  normalize,\n  tokenize,\n  stem,\n  removeStopwords,\n  dict,\n  bow,\n} = require('./lang-functions');\n\nmodule.exports = {\n  LangAll,\n\n  LangAr,\n  NormalizerAr,\n  SentimentAr,\n  StemmerAr,\n  StopwordsAr,\n  TokenizerAr,\n\n  LangBn,\n  NormalizerBn,\n  SentimentBn,\n  StemmerBn,\n  StopwordsBn,\n  TokenizerBn,\n\n  LangCa,\n  NormalizerCa,\n  SentimentCa,\n  StemmerCa,\n  StopwordsCa,\n  TokenizerCa,\n\n  LangCs,\n  NormalizerCs,\n  SentimentCs,\n  StemmerCs,\n  StopwordsCs,\n  TokenizerCs,\n\n  LangDa,\n  NormalizerDa,\n  SentimentDa,\n  StemmerDa,\n  StopwordsDa,\n  TokenizerDa,\n\n  LangDe,\n  NormalizerDe,\n  SentimentDe,\n  StemmerDe,\n  StopwordsDe,\n  TokenizerDe,\n\n  LangEl,\n  NormalizerEl,\n  SentimentEl,\n  StemmerEl,\n  StopwordsEl,\n  TokenizerEl,\n\n  LangEn,\n  NormalizerEn,\n  SentimentEn,\n  StemmerEn,\n  StopwordsEn,\n  TokenizerEn,\n\n  LangEs,\n  NormalizerEs,\n  SentimentEs,\n  StemmerEs,\n  StopwordsEs,\n  TokenizerEs,\n\n  LangEu,\n  NormalizerEu,\n  SentimentEu,\n  StemmerEu,\n  StopwordsEu,\n  TokenizerEu,\n\n  LangFa,\n  NormalizerFa,\n  SentimentFa,\n  StemmerFa,\n  StopwordsFa,\n  TokenizerFa,\n\n  LangFi,\n  NormalizerFi,\n  SentimentFi,\n  StemmerFi,\n  StopwordsFi,\n  TokenizerFi,\n\n  LangFr,\n  NormalizerFr,\n  SentimentFr,\n  StemmerFr,\n  StopwordsFr,\n  TokenizerFr,\n\n  LangGa,\n  NormalizerGa,\n  SentimentGa,\n  StemmerGa,\n  StopwordsGa,\n  TokenizerGa,\n\n  LangGl,\n  NormalizerGl,\n  SentimentGl,\n  StemmerGl,\n  StopwordsGl,\n  TokenizerGl,\n\n  LangHi,\n  NormalizerHi,\n  SentimentHi,\n  StemmerHi,\n  StopwordsHi,\n  TokenizerHi,\n\n  LangHu,\n  NormalizerHu,\n  SentimentHu,\n  StemmerHu,\n  StopwordsHu,\n  TokenizerHu,\n\n  LangHy,\n  NormalizerHy,\n  SentimentHy,\n  StemmerHy,\n  StopwordsHy,\n  TokenizerHy,\n\n  LangIt,\n  NormalizerIt,\n  SentimentIt,\n  StemmerIt,\n  StopwordsIt,\n  TokenizerIt,\n\n  LangId,\n  NormalizerId,\n  SentimentId,\n  StemmerId,\n  StopwordsId,\n  TokenizerId,\n\n  LangJa,\n  NormalizerJa,\n  SentimentJa,\n  StemmerJa,\n  StopwordsJa,\n  TokenizerJa,\n\n  LangKo,\n  NormalizerKo,\n  SentimentKo,\n  StemmerKo,\n  StopwordsKo,\n  TokenizerKo,\n\n  LangLt,\n  NormalizerLt,\n  SentimentLt,\n  StemmerLt,\n  StopwordsLt,\n  TokenizerLt,\n\n  LangMs,\n  NormalizerMs,\n  SentimentMs,\n  StemmerMs,\n  StopwordsMs,\n  TokenizerMs,\n\n  LangNe,\n  NormalizerNe,\n  SentimentNe,\n  StemmerNe,\n  StopwordsNe,\n  TokenizerNe,\n\n  LangNl,\n  NormalizerNl,\n  SentimentNl,\n  StemmerNl,\n  StopwordsNl,\n  TokenizerNl,\n\n  LangNo,\n  NormalizerNo,\n  SentimentNo,\n  StemmerNo,\n  StopwordsNo,\n  TokenizerNo,\n\n  LangPl,\n  NormalizerPl,\n  SentimentPl,\n  StemmerPl,\n  StopwordsPl,\n  TokenizerPl,\n\n  LangPt,\n  NormalizerPt,\n  SentimentPt,\n  StemmerPt,\n  StopwordsPt,\n  TokenizerPt,\n\n  LangRo,\n  NormalizerRo,\n  SentimentRo,\n  StemmerRo,\n  StopwordsRo,\n  TokenizerRo,\n\n  LangRu,\n  NormalizerRu,\n  SentimentRu,\n  StemmerRu,\n  StopwordsRu,\n  TokenizerRu,\n\n  LangSl,\n  NormalizerSl,\n  SentimentSl,\n  StemmerSl,\n  StopwordsSl,\n  TokenizerSl,\n\n  LangSr,\n  NormalizerSr,\n  SentimentSr,\n  StemmerSr,\n  StopwordsSr,\n  TokenizerSr,\n\n  LangSv,\n  NormalizerSv,\n  SentimentSv,\n  StemmerSv,\n  StopwordsSv,\n  TokenizerSv,\n\n  LangTa,\n  NormalizerTa,\n  SentimentTa,\n  StemmerTa,\n  StopwordsTa,\n  TokenizerTa,\n\n  LangTh,\n  NormalizerTh,\n  SentimentTh,\n  StemmerTh,\n  StopwordsTh,\n  TokenizerTh,\n\n  LangTl,\n  NormalizerTl,\n  SentimentTl,\n  StemmerTl,\n  StopwordsTl,\n  TokenizerTl,\n\n  LangTr,\n  NormalizerTr,\n  SentimentTr,\n  StemmerTr,\n  StopwordsTr,\n  TokenizerTr,\n\n  LangUk,\n  NormalizerUk,\n  SentimentUk,\n  StemmerUk,\n  StopwordsUk,\n  TokenizerUk,\n\n  LangZh,\n  NormalizerZh,\n  SentimentZh,\n  StemmerZh,\n  StopwordsZh,\n  TokenizerZh,\n\n  langDict,\n  getNormalizer,\n  getTokenizer,\n  getStemmer,\n  getStopwords,\n  getSentiment,\n  normalize,\n  tokenize,\n  stem,\n  removeStopwords,\n  dict,\n  bow,\n};\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,MAAM;EACJA,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGC,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGN,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJO,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGZ,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJa,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGlB,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJmB,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGxB,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJyB,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG9B,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ+B,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGpC,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJqC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG1C,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ2C,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGhD,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJiD,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGtD,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJuD,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG5D,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ6D,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGlE,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJmE,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGxE,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJyE,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG9E,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ+E,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGpF,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJqF,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG1F,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ2F,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGhG,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJiG,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGtG,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJuG,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG5G,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ6G,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGlH,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJmH,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGxH,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJyH,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG9H,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ+H,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGpI,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJqI,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG1I,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ2I,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGhJ,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJiJ,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGtJ,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJuJ,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG5J,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ6J,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGlK,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJmK,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGxK,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJyK,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG9K,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ+K,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGpL,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJqL,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG1L,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ2L,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGhM,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJiM,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGtM,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJuM,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG5M,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ6M,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGlN,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJmN,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGxN,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJyN,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG9N,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJ+N,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAGpO,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM;EACJqO,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC;AACF,CAAC,GAAG1O,OAAO,CAAC,gBAAgB,CAAC;AAC7B,MAAM2O,OAAO,GAAG3O,OAAO,CAAC,YAAY,CAAC;AAErC,MAAM;EACJ4O,QAAQ;EACRC,aAAa;EACbC,YAAY;EACZC,UAAU;EACVC,YAAY;EACZC,YAAY;EACZC,SAAS;EACTC,QAAQ;EACRC,IAAI;EACJC,eAAe;EACfC,IAAI;EACJC;AACF,CAAC,GAAGvP,OAAO,CAAC,kBAAkB,CAAC;AAE/BwP,MAAM,CAACC,OAAO,GAAG;EACfd,OAAO;EAEPjP,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXE,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXO,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXX,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXO,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXC,MAAM;EACNC,YAAY;EACZC,WAAW;EACXC,SAAS;EACTC,WAAW;EACXC,WAAW;EAEXE,QAAQ;EACRC,aAAa;EACbC,YAAY;EACZC,UAAU;EACVC,YAAY;EACZC,YAAY;EACZC,SAAS;EACTC,QAAQ;EACRC,IAAI;EACJC,eAAe;EACfC,IAAI;EACJC;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}