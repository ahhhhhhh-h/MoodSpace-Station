{"ast":null,"code":"/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n\"use strict\";\n\nvar ViterbiBuilder = require(\"./viterbi/ViterbiBuilder\");\nvar ViterbiSearcher = require(\"./viterbi/ViterbiSearcher\");\nvar IpadicFormatter = require(\"./util/IpadicFormatter\");\nvar PUNCTUATION = /、|。/;\n\n/**\n * Tokenizer\n * @param {DynamicDictionaries} dic Dictionaries used by this tokenizer\n * @constructor\n */\nfunction Tokenizer(dic) {\n  this.token_info_dictionary = dic.token_info_dictionary;\n  this.unknown_dictionary = dic.unknown_dictionary;\n  this.viterbi_builder = new ViterbiBuilder(dic);\n  this.viterbi_searcher = new ViterbiSearcher(dic.connection_costs);\n  this.formatter = new IpadicFormatter(); // TODO Other dictionaries\n}\n\n/**\n * Split into sentence by punctuation\n * @param {string} input Input text\n * @returns {Array.<string>} Sentences end with punctuation\n */\nTokenizer.splitByPunctuation = function (input) {\n  var sentences = [];\n  var tail = input;\n  while (true) {\n    if (tail === \"\") {\n      break;\n    }\n    var index = tail.search(PUNCTUATION);\n    if (index < 0) {\n      sentences.push(tail);\n      break;\n    }\n    sentences.push(tail.substring(0, index + 1));\n    tail = tail.substring(index + 1);\n  }\n  return sentences;\n};\n\n/**\n * Tokenize text\n * @param {string} text Input text to analyze\n * @returns {Array} Tokens\n */\nTokenizer.prototype.tokenize = function (text) {\n  var sentences = Tokenizer.splitByPunctuation(text);\n  var tokens = [];\n  for (var i = 0; i < sentences.length; i++) {\n    var sentence = sentences[i];\n    this.tokenizeForSentence(sentence, tokens);\n  }\n  return tokens;\n};\nTokenizer.prototype.tokenizeForSentence = function (sentence, tokens) {\n  if (tokens == null) {\n    tokens = [];\n  }\n  var lattice = this.getLattice(sentence);\n  var best_path = this.viterbi_searcher.search(lattice);\n  var last_pos = 0;\n  if (tokens.length > 0) {\n    last_pos = tokens[tokens.length - 1].word_position;\n  }\n  for (var j = 0; j < best_path.length; j++) {\n    var node = best_path[j];\n    var token, features, features_line;\n    if (node.type === \"KNOWN\") {\n      features_line = this.token_info_dictionary.getFeatures(node.name);\n      if (features_line == null) {\n        features = [];\n      } else {\n        features = features_line.split(\",\");\n      }\n      token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, features);\n    } else if (node.type === \"UNKNOWN\") {\n      // Unknown word\n      features_line = this.unknown_dictionary.getFeatures(node.name);\n      if (features_line == null) {\n        features = [];\n      } else {\n        features = features_line.split(\",\");\n      }\n      token = this.formatter.formatUnknownEntry(node.name, last_pos + node.start_pos, node.type, features, node.surface_form);\n    } else {\n      // TODO User dictionary\n      token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, []);\n    }\n    tokens.push(token);\n  }\n  return tokens;\n};\n\n/**\n * Build word lattice\n * @param {string} text Input text to analyze\n * @returns {ViterbiLattice} Word lattice\n */\nTokenizer.prototype.getLattice = function (text) {\n  return this.viterbi_builder.build(text);\n};\nmodule.exports = Tokenizer;","map":{"version":3,"names":["ViterbiBuilder","require","ViterbiSearcher","IpadicFormatter","PUNCTUATION","Tokenizer","dic","token_info_dictionary","unknown_dictionary","viterbi_builder","viterbi_searcher","connection_costs","formatter","splitByPunctuation","input","sentences","tail","index","search","push","substring","prototype","tokenize","text","tokens","i","length","sentence","tokenizeForSentence","lattice","getLattice","best_path","last_pos","word_position","j","node","token","features","features_line","type","getFeatures","name","split","formatEntry","start_pos","formatUnknownEntry","surface_form","build","module","exports"],"sources":["/Users/zyq/Desktop/大二下/暑期实习/moonshot project/node_modules/kuromoji/src/Tokenizer.js"],"sourcesContent":["/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n\"use strict\";\n\nvar ViterbiBuilder = require(\"./viterbi/ViterbiBuilder\");\nvar ViterbiSearcher = require(\"./viterbi/ViterbiSearcher\");\nvar IpadicFormatter = require(\"./util/IpadicFormatter\");\n\nvar PUNCTUATION = /、|。/;\n\n/**\n * Tokenizer\n * @param {DynamicDictionaries} dic Dictionaries used by this tokenizer\n * @constructor\n */\nfunction Tokenizer(dic) {\n    this.token_info_dictionary = dic.token_info_dictionary;\n    this.unknown_dictionary = dic.unknown_dictionary;\n    this.viterbi_builder = new ViterbiBuilder(dic);\n    this.viterbi_searcher = new ViterbiSearcher(dic.connection_costs);\n    this.formatter = new IpadicFormatter();  // TODO Other dictionaries\n}\n\n/**\n * Split into sentence by punctuation\n * @param {string} input Input text\n * @returns {Array.<string>} Sentences end with punctuation\n */\nTokenizer.splitByPunctuation = function (input) {\n    var sentences = [];\n    var tail = input;\n    while (true) {\n        if (tail === \"\") {\n            break;\n        }\n        var index = tail.search(PUNCTUATION);\n        if (index < 0) {\n            sentences.push(tail);\n            break;\n        }\n        sentences.push(tail.substring(0, index + 1));\n        tail = tail.substring(index + 1);\n    }\n    return sentences;\n};\n\n/**\n * Tokenize text\n * @param {string} text Input text to analyze\n * @returns {Array} Tokens\n */\nTokenizer.prototype.tokenize = function (text) {\n    var sentences = Tokenizer.splitByPunctuation(text);\n    var tokens = [];\n    for (var i = 0; i < sentences.length; i++) {\n        var sentence = sentences[i];\n        this.tokenizeForSentence(sentence, tokens);\n    }\n    return tokens;\n};\n\nTokenizer.prototype.tokenizeForSentence = function (sentence, tokens) {\n    if (tokens == null) {\n        tokens = [];\n    }\n    var lattice = this.getLattice(sentence);\n    var best_path = this.viterbi_searcher.search(lattice);\n    var last_pos = 0;\n    if (tokens.length > 0) {\n        last_pos = tokens[tokens.length - 1].word_position;\n    }\n\n    for (var j = 0; j < best_path.length; j++) {\n        var node = best_path[j];\n\n        var token, features, features_line;\n        if (node.type === \"KNOWN\") {\n            features_line = this.token_info_dictionary.getFeatures(node.name);\n            if (features_line == null) {\n                features = [];\n            } else {\n                features = features_line.split(\",\");\n            }\n            token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, features);\n        } else if (node.type === \"UNKNOWN\") {\n            // Unknown word\n            features_line = this.unknown_dictionary.getFeatures(node.name);\n            if (features_line == null) {\n                features = [];\n            } else {\n                features = features_line.split(\",\");\n            }\n            token = this.formatter.formatUnknownEntry(node.name, last_pos + node.start_pos, node.type, features, node.surface_form);\n        } else {\n            // TODO User dictionary\n            token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, []);\n        }\n\n        tokens.push(token);\n    }\n\n    return tokens;\n};\n\n/**\n * Build word lattice\n * @param {string} text Input text to analyze\n * @returns {ViterbiLattice} Word lattice\n */\nTokenizer.prototype.getLattice = function (text) {\n    return this.viterbi_builder.build(text);\n};\n\nmodule.exports = Tokenizer;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAY;;AAEZ,IAAIA,cAAc,GAAGC,OAAO,CAAC,0BAA0B,CAAC;AACxD,IAAIC,eAAe,GAAGD,OAAO,CAAC,2BAA2B,CAAC;AAC1D,IAAIE,eAAe,GAAGF,OAAO,CAAC,wBAAwB,CAAC;AAEvD,IAAIG,WAAW,GAAG,KAAK;;AAEvB;AACA;AACA;AACA;AACA;AACA,SAASC,SAASA,CAACC,GAAG,EAAE;EACpB,IAAI,CAACC,qBAAqB,GAAGD,GAAG,CAACC,qBAAqB;EACtD,IAAI,CAACC,kBAAkB,GAAGF,GAAG,CAACE,kBAAkB;EAChD,IAAI,CAACC,eAAe,GAAG,IAAIT,cAAc,CAACM,GAAG,CAAC;EAC9C,IAAI,CAACI,gBAAgB,GAAG,IAAIR,eAAe,CAACI,GAAG,CAACK,gBAAgB,CAAC;EACjE,IAAI,CAACC,SAAS,GAAG,IAAIT,eAAe,CAAC,CAAC,CAAC,CAAE;AAC7C;;AAEA;AACA;AACA;AACA;AACA;AACAE,SAAS,CAACQ,kBAAkB,GAAG,UAAUC,KAAK,EAAE;EAC5C,IAAIC,SAAS,GAAG,EAAE;EAClB,IAAIC,IAAI,GAAGF,KAAK;EAChB,OAAO,IAAI,EAAE;IACT,IAAIE,IAAI,KAAK,EAAE,EAAE;MACb;IACJ;IACA,IAAIC,KAAK,GAAGD,IAAI,CAACE,MAAM,CAACd,WAAW,CAAC;IACpC,IAAIa,KAAK,GAAG,CAAC,EAAE;MACXF,SAAS,CAACI,IAAI,CAACH,IAAI,CAAC;MACpB;IACJ;IACAD,SAAS,CAACI,IAAI,CAACH,IAAI,CAACI,SAAS,CAAC,CAAC,EAAEH,KAAK,GAAG,CAAC,CAAC,CAAC;IAC5CD,IAAI,GAAGA,IAAI,CAACI,SAAS,CAACH,KAAK,GAAG,CAAC,CAAC;EACpC;EACA,OAAOF,SAAS;AACpB,CAAC;;AAED;AACA;AACA;AACA;AACA;AACAV,SAAS,CAACgB,SAAS,CAACC,QAAQ,GAAG,UAAUC,IAAI,EAAE;EAC3C,IAAIR,SAAS,GAAGV,SAAS,CAACQ,kBAAkB,CAACU,IAAI,CAAC;EAClD,IAAIC,MAAM,GAAG,EAAE;EACf,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGV,SAAS,CAACW,MAAM,EAAED,CAAC,EAAE,EAAE;IACvC,IAAIE,QAAQ,GAAGZ,SAAS,CAACU,CAAC,CAAC;IAC3B,IAAI,CAACG,mBAAmB,CAACD,QAAQ,EAAEH,MAAM,CAAC;EAC9C;EACA,OAAOA,MAAM;AACjB,CAAC;AAEDnB,SAAS,CAACgB,SAAS,CAACO,mBAAmB,GAAG,UAAUD,QAAQ,EAAEH,MAAM,EAAE;EAClE,IAAIA,MAAM,IAAI,IAAI,EAAE;IAChBA,MAAM,GAAG,EAAE;EACf;EACA,IAAIK,OAAO,GAAG,IAAI,CAACC,UAAU,CAACH,QAAQ,CAAC;EACvC,IAAII,SAAS,GAAG,IAAI,CAACrB,gBAAgB,CAACQ,MAAM,CAACW,OAAO,CAAC;EACrD,IAAIG,QAAQ,GAAG,CAAC;EAChB,IAAIR,MAAM,CAACE,MAAM,GAAG,CAAC,EAAE;IACnBM,QAAQ,GAAGR,MAAM,CAACA,MAAM,CAACE,MAAM,GAAG,CAAC,CAAC,CAACO,aAAa;EACtD;EAEA,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,SAAS,CAACL,MAAM,EAAEQ,CAAC,EAAE,EAAE;IACvC,IAAIC,IAAI,GAAGJ,SAAS,CAACG,CAAC,CAAC;IAEvB,IAAIE,KAAK,EAAEC,QAAQ,EAAEC,aAAa;IAClC,IAAIH,IAAI,CAACI,IAAI,KAAK,OAAO,EAAE;MACvBD,aAAa,GAAG,IAAI,CAAC/B,qBAAqB,CAACiC,WAAW,CAACL,IAAI,CAACM,IAAI,CAAC;MACjE,IAAIH,aAAa,IAAI,IAAI,EAAE;QACvBD,QAAQ,GAAG,EAAE;MACjB,CAAC,MAAM;QACHA,QAAQ,GAAGC,aAAa,CAACI,KAAK,CAAC,GAAG,CAAC;MACvC;MACAN,KAAK,GAAG,IAAI,CAACxB,SAAS,CAAC+B,WAAW,CAACR,IAAI,CAACM,IAAI,EAAET,QAAQ,GAAGG,IAAI,CAACS,SAAS,EAAET,IAAI,CAACI,IAAI,EAAEF,QAAQ,CAAC;IACjG,CAAC,MAAM,IAAIF,IAAI,CAACI,IAAI,KAAK,SAAS,EAAE;MAChC;MACAD,aAAa,GAAG,IAAI,CAAC9B,kBAAkB,CAACgC,WAAW,CAACL,IAAI,CAACM,IAAI,CAAC;MAC9D,IAAIH,aAAa,IAAI,IAAI,EAAE;QACvBD,QAAQ,GAAG,EAAE;MACjB,CAAC,MAAM;QACHA,QAAQ,GAAGC,aAAa,CAACI,KAAK,CAAC,GAAG,CAAC;MACvC;MACAN,KAAK,GAAG,IAAI,CAACxB,SAAS,CAACiC,kBAAkB,CAACV,IAAI,CAACM,IAAI,EAAET,QAAQ,GAAGG,IAAI,CAACS,SAAS,EAAET,IAAI,CAACI,IAAI,EAAEF,QAAQ,EAAEF,IAAI,CAACW,YAAY,CAAC;IAC3H,CAAC,MAAM;MACH;MACAV,KAAK,GAAG,IAAI,CAACxB,SAAS,CAAC+B,WAAW,CAACR,IAAI,CAACM,IAAI,EAAET,QAAQ,GAAGG,IAAI,CAACS,SAAS,EAAET,IAAI,CAACI,IAAI,EAAE,EAAE,CAAC;IAC3F;IAEAf,MAAM,CAACL,IAAI,CAACiB,KAAK,CAAC;EACtB;EAEA,OAAOZ,MAAM;AACjB,CAAC;;AAED;AACA;AACA;AACA;AACA;AACAnB,SAAS,CAACgB,SAAS,CAACS,UAAU,GAAG,UAAUP,IAAI,EAAE;EAC7C,OAAO,IAAI,CAACd,eAAe,CAACsC,KAAK,CAACxB,IAAI,CAAC;AAC3C,CAAC;AAEDyB,MAAM,CAACC,OAAO,GAAG5C,SAAS","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}